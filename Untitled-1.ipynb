{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img, text=None, should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(\n",
    "            75,\n",
    "            8,\n",
    "            text,\n",
    "            style=\"italic\",\n",
    "            fontweight=\"bold\",\n",
    "            bbox={\"facecolor\": \"white\", \"alpha\": 0.8, \"pad\": 10},\n",
    "        )\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_plot(iteration, loss):\n",
    "    plt.plot(iteration, loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"Contrastive loss function\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean(\n",
    "            (1 - label) * torch.pow(euclidean_distance, 2)\n",
    "            + (label)\n",
    "            * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"/content/gdrive/My Drive/data/sign_data/sign_data/train\"\n",
    "training_csv = \"/content/gdrive/My Drive/data/sign_data/sign_data/train_data.csv\"\n",
    "testing_csv = \"/content/gdrive/My Drive/data/sign_data/sign_data/test_data.csv\"\n",
    "testing_dir = \"/content/gdrive/My Drive/data/sign_data/sign_data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the dataset\n",
    "training_dir = training_dir\n",
    "testing_dir = testing_dir\n",
    "training_csv = training_csv\n",
    "testing_csv = testing_csv\n",
    "\n",
    "\n",
    "# preprocessing and loading the dataset\n",
    "class SiameseDataset:\n",
    "    def __init__(self, training_csv=None, training_dir=None, transform=None):\n",
    "        # used to prepare the labels and images path\n",
    "        self.train_df = pd.read_csv(training_csv)\n",
    "        self.train_df.columns = [\"image1\", \"image2\", \"label\"]\n",
    "        self.train_dir = training_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # getting the image path\n",
    "        image1_path = os.path.join(self.train_dir, self.train_df.iat[index, 0])\n",
    "        image2_path = os.path.join(self.train_dir, self.train_df.iat[index, 1])\n",
    "\n",
    "        # Loading the image\n",
    "        img0 = Image.open(image1_path)\n",
    "        img1 = Image.open(image2_path)\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        # Apply image transformations\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "\n",
    "        return (\n",
    "            img0,\n",
    "            img1,\n",
    "            torch.from_numpy(\n",
    "                np.array([int(self.train_df.iat[index, 2])], dtype=np.float32)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_df)\n",
    "\n",
    "\n",
    "# Load the the dataset from raw image folders\n",
    "siamese_dataset = SiameseDataset(\n",
    "    training_csv,\n",
    "    training_dir,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the sample of images and to check whether its loading properly\n",
    "vis_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=8)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "\n",
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0], example_batch[1]), 0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create a siamese network\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout(p=0.3),\n",
    "\n",
    "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout(p=0.3),\n",
    "\n",
    "        )\n",
    "\n",
    "        # Defining the fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(30976, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(128,2))\n",
    "\n",
    "\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        # Forward pass\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # forward pass of input 1\n",
    "        output1 = self.forward_once(input1)\n",
    "        # forward pass of input 2\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "\n",
    " # Load the dataset as pytorch tensors using dataloader\n",
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Declare Siamese Network\n",
    "net = SiameseNetwork().cuda()\n",
    "# Decalre Loss Function\n",
    "criterion = ContrastiveLoss()\n",
    "# Declare Optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train the model\n",
    "def train(train_dataloader):\n",
    "    loss=[]\n",
    "    counter=[]\n",
    "    iteration_number = 0\n",
    "    for i, data in enumerate(train_dataloader,0):\n",
    "      img0, img1 , label = data\n",
    "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "      optimizer.zero_grad()\n",
    "      output1,output2 = net(img0,img1)\n",
    "      loss_contrastive = criterion(output1,output2,label)\n",
    "      loss_contrastive.backward()\n",
    "      optimizer.step()\n",
    "      loss.append(loss_contrastive.item())\n",
    "    loss = np.array(loss)\n",
    "    return loss.mean()/len(train_dataloader)\n",
    "\n",
    "\n",
    "def eval(eval_dataloader):\n",
    "    loss=[]\n",
    "    counter=[]\n",
    "    iteration_number = 0\n",
    "    for i, data in enumerate(eval_dataloader,0):\n",
    "      img0, img1 , label = data\n",
    "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "      output1,output2 = net(img0,img1)\n",
    "      loss_contrastive = criterion(output1,output2,label)\n",
    "      loss.append(loss_contrastive.item())\n",
    "    loss = np.array(loss)\n",
    "    return loss.mean()/len(eval_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,epochs):\n",
    "  best_eval_loss = 9999\n",
    "  train_loss = train(train_dataloader)\n",
    "  eval_loss = eval(train_dataloader)\n",
    "\n",
    "  print(f\"Training loss{train_loss}\")\n",
    "  print(\"-\"*20)\n",
    "  print(f\"Eval loss{eval_loss}\")\n",
    "\n",
    "  if eval_loss<best_eval_loss:\n",
    "    best_eval_loss = eval_loss\n",
    "    print(\"-\"*20)\n",
    "    print(f\"Best Eval loss{best_eval_loss}\")\n",
    "    torch.save(net.state_dict(), \"/content/model.pth\")\n",
    "    print(\"Model Saved Successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SiameseNetwork()\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/data/sign_data/sign_data/model.pt'), map_location=device)\n",
    "# model = torch.load('/content/gdrive/MyDrive/data/sign_data/sign_data/model.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_accuracy_roc(predictions, labels):\n",
    "    dmax = np.max(predictions)\n",
    "    dmin = np.min(predictions)\n",
    "    nsame = np.sum(labels == 1)\n",
    "    ndiff = np.sum(labels == 0)\n",
    "    step = 0.001\n",
    "    max_acc = 0\n",
    "\n",
    "    d_optimal = 0\n",
    "    for d in np.arange(dmin, dmax + step, step):\n",
    "        idx1 = predictions.ravel() <= d\n",
    "        idx2 = predictions.ravel() > d\n",
    "\n",
    "        tpr = float(np.sum(labels[idx1] == 1)) / nsame\n",
    "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n",
    "\n",
    "        acc = 0.5 * (tpr + tnr)\n",
    "\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            d_optimal = d\n",
    "\n",
    "    return max_acc, d_optimal\n",
    "\n",
    "\n",
    "batch_avg_acc = 0\n",
    "batch_avg_d = 0\n",
    "n_batch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SiameseDataset(\n",
    "    training_csv=testing_csv,\n",
    "    training_dir=testing_dir,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "batch_avg_acc = 0\n",
    "batch_avg_d = 0\n",
    "n_batch = 0\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, num_workers=6, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    x0, x1, label = data\n",
    "    concat = torch.cat((x0, x1), 0)\n",
    "    output1, output2 = model(x0, x1)\n",
    "    labels=label.long()\n",
    "    eucledian_distance = F.pairwise_distance(output1, output2)\n",
    "    acc, d = compute_accuracy_roc(eucledian_distance.detach().numpy(), labels.detach().numpy())\n",
    "    print('Max accuracy for batch {} = {} at d = {}'.format(i, acc, d))\n",
    "    batch_avg_acc += acc\n",
    "    batch_avg_d += d\n",
    "    n_batch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Avg acc across all batches={} at d={}'.format(batch_avg_acc / n_batch, batch_avg_d / n_batch))\n",
    "d=batch_avg_d / n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SiameseDataset(\n",
    "    training_csv=testing_csv,\n",
    "    training_dir=testing_dir,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, num_workers=6, batch_size=8, shuffle=True)\n",
    "\n",
    "total_count = 0\n",
    "correct_count=0\n",
    "threshold=d\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    x0, x1, label = data\n",
    "    concat = torch.cat((x0, x1), 0)\n",
    "    output1, output2 = model(x0.to(device), x1.to(device))\n",
    "\n",
    "    eucledian_distance = F.pairwise_distance(output1, output2)\n",
    "\n",
    "    if label == torch.FloatTensor([[0]]):\n",
    "        label = \"Original Pair Of Signature\"\n",
    "    else:\n",
    "        label = \"Forged Pair Of Signature\"\n",
    "\n",
    "\n",
    "    if eucledian_distance.item() <= threshold:\n",
    "        predicted_label = \"Original Pair Of Signature\"\n",
    "    else:\n",
    "        predicted_label = \"Forged Pair Of Signature\"\n",
    "\n",
    "    if predicted_label == label:\n",
    "        correct_count += 1\n",
    "\n",
    "    total_count += 1\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(concat))\n",
    "    print(\"Predicted Label:-\", predicted_label)\n",
    "    print(\"Actual Label:-\", label)\n",
    "    print(\"Predicted Eucledian Distance:-\", eucledian_distance.item())\n",
    "\n",
    "\n",
    "accuracy = correct_count / total_count\n",
    "print(\"Accuracy:-\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
